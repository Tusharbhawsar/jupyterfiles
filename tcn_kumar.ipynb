{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 14:38:52.294647: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/link-lap-24/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-12-15 14:38:52.294674: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import subprocess as sp\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_virtual_device_configuration(\n",
    "#         gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=9120)])\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "MAX_SEQ_LENGTH = 16\n",
    "WINDOW_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of df:: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress:   0%|                                         | 0/189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_path:: /home/link-lap-24/Downloads/tagging/ICC/clips/262.mp4\n",
      "video_info: {'programs': [], 'streams': [{'width': 1280, 'height': 720, 'duration': '196.240000'}]}\n",
      "duration of video:: 196.240000\n",
      "event time:: 51.7\n",
      "start_times before event:; [49.7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   1%|▏                                | 1/189 [00:00<01:01,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of frame_seq:: 16\n",
      "Data Shape: (1, 16, 224, 224, 3)\n",
      "Labels Shape: (1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_video(path, event_time, window_size=WINDOW_SIZE, max_frames=MAX_SEQ_LENGTH, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    # get frame dimensions from video\n",
    "    path1 = path.split('/')[-1].split('.')[0]\n",
    "    command = [ 'ffprobe','-v', 'error','-select_streams', 'v:0','-show_entries', 'stream=width,height,duration',\n",
    "                '-of', 'json', path ]\n",
    "    pipe = sp.Popen(command, stdout = sp.PIPE, bufsize=20**5)\n",
    "    video_info = json.loads(pipe.stdout.read())\n",
    "    print(\"video_info:\",video_info)\n",
    "    width = video_info['streams'][0]['width']\n",
    "    height = video_info['streams'][0]['height']\n",
    "    try:\n",
    "        duration = video_info['streams'][0]['duration']\n",
    "        print(\"duration of video::\",duration)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    pipe.stdout.flush()\n",
    "    \n",
    "    start_times = []\n",
    "    frame_seq = []\n",
    "    fps = int(MAX_SEQ_LENGTH/window_size)\n",
    "    \n",
    "    event_time =51.7\n",
    "    print(\"event time::\",event_time)\n",
    "    if event_time < window_size:\n",
    "        print(\"window size greater than event time\")\n",
    "        return start_times\n",
    "    start_times.append(event_time - window_size)\n",
    "    print(\"start_times before event:;\",start_times)\n",
    "    for start_time in start_times:\n",
    "        #reading video event at given time\n",
    "        command = [ 'ffmpeg','-loglevel', 'quiet','-ss', str(start_time),'-t', str(window_size),'-i', path,\n",
    "                    # '-r', str(fps),\n",
    "                    '-vf', 'fps={}'.format(fps),\n",
    "                    '-f', 'image2pipe',\n",
    "                    '-pix_fmt', 'rgb24',\n",
    "                    '-vcodec', 'rawvideo', '-' ]\n",
    "        pipe = sp.Popen(command, stdout = sp.PIPE, bufsize=10**5)\n",
    "\n",
    "        frames = []\n",
    "        try:\n",
    "            while True:\n",
    "                raw_image = pipe.stdout.read(width*height*3)\n",
    "                if not raw_image:\n",
    "                    break\n",
    "                frame =  np.frombuffer(raw_image, dtype='uint8')\n",
    "                frame = frame.reshape((height,width,3))\n",
    "                frame = cv2.resize(frame, resize)\n",
    "                #print(\"type of frame::\",type(frame))\n",
    "                frames.append(frame)\n",
    "                if len(frames) == max_frames:\n",
    "                    break\n",
    "        finally:\n",
    "            pipe.stdout.flush()\n",
    "        frame_seq.append(np.array(frames))\n",
    "        \n",
    "        print(\"len of frame_seq::\",len(np.array(frames)))\n",
    "        for idx, frame in enumerate(frames):\n",
    "            #image = cv2.imread(frame)\n",
    "            #print(\"frame shape::\",frame.shape)\n",
    "#             if(len(frame.shape)<3):\n",
    "#                   print('gray')\n",
    "#             elif len(frame.shape)==3:\n",
    "#                   print ('Color(RGB)')\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Use the cvtColor() function to grayscale the image\n",
    "            #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            #cv2.imwrite(os.path.join('seq_frames','input_frames_train', f'{path1}_{idx+1}.png'), frame)\n",
    "            cv2.imwrite(os.path.join('seq_frames','input_frames_train', f'{idx+1}.png'), frame)\n",
    "    \n",
    "\n",
    "    return frame_seq\n",
    "def prepare_all_videos(df):\n",
    "    input_data, labels = [], []\n",
    "    with tqdm(total=len(df), desc=\"Progress\") as pbar:\n",
    "        for idx, video_name, label, event_time in df.itertuples():\n",
    "            #video_path = os.path.join(root_dir,video_name)\n",
    "            #video_path=video_name\n",
    "            video_path = \"/home/link-lap-24/Downloads/tagging/ICC/clips/262.mp4\"\n",
    "            print(\"video_path::\",video_path)\n",
    "            frame_seq = load_video(video_path, event_time)\n",
    "            if frame_seq:\n",
    "                for frame_arr in frame_seq:\n",
    "                    #print(\"frame_arr shape::\",frame_arr.shape) nd array\n",
    "                    input_data.append(frame_arr)                    \n",
    "                    labels.append(label)\n",
    "                    \n",
    "            pbar.update(1)\n",
    "            break\n",
    "    #input_data = np.array(input_data,dtype=object)\n",
    "    input_data=np.array(input_data).astype('float32')\n",
    "\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    return input_data, labels\n",
    "\n",
    "# load video data\n",
    "df = pd.read_csv('/home/link-lap-24/Downloads/tagging/ICC/Updated_ICC.csv')\n",
    "print(\"length of df::\",len(df))\n",
    "#data_dir = os.path.join('test/data1', 'videos')\n",
    "input_data, labels = prepare_all_videos(df)\n",
    "\n",
    "print(f\"Data Shape: {input_data.shape}\")\n",
    "print(f\"Labels Shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save train data\n",
    "np.savez_compressed('array_data/train_data_celeb_no_celeb_dec_14.npz', input_data, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load  data\n",
    "#npz contains collection of numpy arrays\n",
    "data = np.load('array_data/train_data_celeb_no_celeb_dec_14.npz')\n",
    "#p = np.random.permutation(len(data['arr_1']))\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "train_data = data['arr_0']\n",
    "train_labels = data['arr_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(train_labels))\n",
    "train_data = train_data[p]\n",
    "train_labels = train_labels[p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data Shape: (527, 16, 224, 224, 3)\n",
      "Labels Shape: (527, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data/255\n",
    "#train_labels = train_labels[...,None]\n",
    "train_labels = to_categorical(train_labels,num_classes=2)\n",
    "print(f\"train data Shape: {train_data.shape}\")\n",
    "print(f\"Labels Shape: {train_labels.shape}\")\n",
    "CLASSES_LIST = [\"Batsman_Celebration\",\"No_Celebration\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_model(seq_length, img_size):\n",
    "    np.random.seed(1234)\n",
    "    base_model = tf.keras.applications.vgg19.VGG19(include_top=False, weights='imagenet', input_shape=(img_size, img_size, 3))\n",
    "    # Freeze all the layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    cnn = keras.models.Sequential()\n",
    "    cnn.add(base_model)\n",
    "    cnn.add(keras.layers.Flatten())\n",
    "    \n",
    "    # define LSTM model\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.TimeDistributed(cnn,  input_shape=(seq_length, img_size, img_size, 3)))\n",
    "    model.add(keras.layers.LSTM(40, return_sequences=True))\n",
    "    model.add(keras.layers.TimeDistributed(keras.layers.Dense(160, activation='relu')))\n",
    "    model.add(keras.layers.GlobalAveragePooling1D(name=\"global\"))\n",
    "    # model.add(keras.layers.Dropout(0.3))\n",
    "    # model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(len(CLASSES_LIST), activation=\"sigmoid\" , name=\"output\"))\n",
    "\n",
    "    adam = keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[\"accuracy\"])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 30\n",
    "MODEL_PATH = 'weights/lstm_celeb_vs_noceleb_dec14_new_arch_vgg19.hdf5'\n",
    "\n",
    "def fit_model():\n",
    "    model = get_lstm_model(MAX_SEQ_LENGTH, IMG_SIZE)\n",
    "\n",
    "    earlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=1e-5, verbose=0, mode='min')\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(MODEL_PATH, save_best_only=True, monitor='val_loss', mode='min')\n",
    "    reduce_lr_loss = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=2, factor=0.5, min_lr=0.0000001)\n",
    "\n",
    "    history = model.fit(train_data, train_labels, batch_size=BATCH_SIZE, validation_split=0.3,\n",
    "                    epochs=EPOCHS, callbacks=[earlyStopping, checkpoint, reduce_lr_loss])\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (527, 16, 224, 224, 3)\n",
      "Labels Shape: (527, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 20:20:35.441147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 20:20:35.462308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 20:20:35.462689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 20:20:35.464482: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-14 20:20:35.466097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 20:20:35.466384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 20:20:35.466631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 20:20:35.787507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 20:20:35.787642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 20:20:35.787728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 20:20:35.787799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9646 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 16, 25088)         20024384  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 16, 40)            4020640   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 16, 160)           6560      \n",
      "_________________________________________________________________\n",
      "global (GlobalAveragePooling (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              164864    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 24,916,490\n",
      "Trainable params: 4,892,106\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 20:20:36.344356: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 3545235456 exceeds 10% of free system memory.\n",
      "2022-12-14 20:20:37.914447: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 3545235456 exceeds 10% of free system memory.\n",
      "2022-12-14 20:20:39.025603: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 20:20:40.591105: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/368 [..............................] - ETA: 16s - loss: 0.7029 - accuracy: 0.3333      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda-11.1/lib64/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "2022-12-14 20:20:42.464036: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 29s 68ms/step - loss: 0.6938 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5283\n",
      "Epoch 2/100\n",
      "368/368 [==============================] - 24s 64ms/step - loss: 0.6943 - accuracy: 0.5163 - val_loss: 0.6930 - val_accuracy: 0.5849\n",
      "Epoch 3/100\n",
      "368/368 [==============================] - 24s 64ms/step - loss: 0.6948 - accuracy: 0.4565 - val_loss: 0.6933 - val_accuracy: 0.4717\n",
      "Epoch 4/100\n",
      "368/368 [==============================] - 24s 65ms/step - loss: 0.6938 - accuracy: 0.5082 - val_loss: 0.6933 - val_accuracy: 0.5283\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data Shape: {train_data.shape}\")\n",
    "print(f\"Labels Shape: {train_labels.shape}\")\n",
    "history, model = fit_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend([\"accuracy\", \"val_accuracy\"], loc =\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('accuracy_valaccurac.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend([\"loss\", \"val_loss\"], loc =\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('loss_valloss.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
